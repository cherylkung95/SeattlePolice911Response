{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file takes the original dataset from Kaggle and converts the dataset into Python-readable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\chery\\\\Documents\\\\SeattlePolice911Response')\n",
    "from utils.baseML import BaseML\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chery\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "spir_original = pd.read_csv(\"Seattle_Police_Department_911_Incident_Response.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CAD CDW ID', 'CAD Event Number', 'General Offense Number',\n",
      "       'Event Clearance Code', 'Event Clearance Description',\n",
      "       'Event Clearance SubGroup', 'Event Clearance Group',\n",
      "       'Event Clearance Date', 'Hundred Block Location', 'District/Sector',\n",
      "       'Zone/Beat', 'Census Tract', 'Longitude', 'Latitude',\n",
      "       'Incident Location', 'Initial Type Description',\n",
      "       'Initial Type Subgroup', 'Initial Type Group', 'At Scene Time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(spir_original.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Drop unused Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns= ['CAD CDW ID', 'CAD Event Number', 'General Offense Number', 'Hundred Block Location', 'District/Sector',\n",
    "       'Zone/Beat', 'Longitude', 'Latitude',\n",
    "       'Incident Location']\n",
    "\n",
    "spir_drop_unused_col = spir_original.drop(labels=drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of unique census tracts. This is used to pull data from the US Census API 5 year American Community Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_tracts = spir_drop_unused_col[\"Census Tract\"].unique()\n",
    "census_tracts = pd.DataFrame(census_tracts, columns=[\"census_tracts\"])\n",
    "census_tracts.dropna(axis =0, inplace=True)\n",
    "census_tracts.census_tracts=census_tracts.census_tracts.apply(format_tract)\n",
    "census_tracts.census_tracts = pd.Series(census_tracts.census_tracts.unique())\n",
    "census_tracts.dropna(axis=0, inplace=True)\n",
    "census_tracts.to_csv(\"census_tracts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seattle_Police_ML(BaseML):\n",
    "\n",
    "    def dayDifference(self, fdate, ldate):\n",
    "        delta = ldate - fdate\n",
    "        return(delta)\n",
    "\n",
    "    def transform_times(self):\n",
    "        self.df[\"at_scene_datetime\"] = self.df.apply(lambda x: x.At_Scene_Date + \"T\" + x.At_Scene_Time, axis=1)\n",
    "        self.df['at_scene_temp'] = self.df.at_scene_datetime.apply(lambda x: datetime.fromisoformat(x))\n",
    "        self.df.Event_Clearance_Date.fillna(\"2021-05-13\", inplace=True)\n",
    "        self.df.Event_Clearance_Time.fillna(\"00:00:00\", inplace=True)\n",
    "        #self.df[[\"Event_Clearance_Date\", \"Event_Clearance_Time\"]] = self.df[[\"Event_Clearance_Date\", \"Event_Clearance_Time\"]].astype(str)\n",
    "        #print(spir.df.Event_Clearance_Date.dtype)\n",
    "        self.df[\"event_clear_datetime\"] = self.df.apply(lambda x: x.Event_Clearance_Date + \"T\" + x.Event_Clearance_Time, axis=1)\n",
    "        self.df['event_clear_temp'] = self.df.event_clear_datetime.apply(lambda x: datetime.fromisoformat(x))\n",
    "        self.df['time_at_scene'] = self.df.apply(lambda x: pd.to_timedelta(self.dayDifference(x[\"at_scene_temp\"], x[\"event_clear_temp\"])), axis = 1)\n",
    "        self.df.drop([\"At_Scene_Date\",\"At_Scene_Time\", \"Event_Clearance_Date\", \"Event_Clearance_Time\"], axis = 1, inplace = True)\n",
    "        #self.df.drop(self.df[self.df['Schedule_to_appt_days'] < 0].index, inplace = True)\n",
    "        #self.df.dropna(inplace=True)\n",
    "        print(self.df.sample(3))\n",
    "\n",
    "    def simplify_times(self):\n",
    "        bins = (\n",
    "            pd.Timedelta(minutes = 0),\n",
    "            pd.Timedelta(minutes = 30),\n",
    "            pd.Timedelta(minutes = 60),\n",
    "            pd.Timedelta(hours = 4),\n",
    "            pd.Timedelta(hours = 8),\n",
    "            pd.Timedelta(hours = 12),\n",
    "            pd.Timedelta(days = 1),\n",
    "            pd.Timedelta(days = 36500)\n",
    "        )\n",
    "\n",
    "        labels = ['< 30min', '30-60min','1-4hrs', '4-8hrs','8-12hrs','12-24hrs', '24hrs+']\n",
    "\n",
    "        return pd.cut(self.df['time_at_scene'], bins, labels = labels)\n",
    "    \n",
    "\n",
    "    def encode_features(self):\n",
    "        features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "        df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "        \n",
    "        for feature in features:\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            le = le.fit(df_combined[feature])\n",
    "            df_train[feature] = le.transform(df_train[feature])\n",
    "            df_test[feature] = le.transform(df_test[feature])\n",
    "        return df_train, df_test\n",
    "        \n",
    "        data_train, data_test = encode_features(data_train, data_test)\n",
    "        data_train.head()\n",
    "\n",
    "    def normalize_features(self):\n",
    "        scaler = preprocessing.StandardScaler().fit(self.df)\n",
    "        df_scaled = scaler.transform(self.df)\n",
    "        self.df = pd.DataFrame(df_scaled, columns = self.df.columns, dtype= 'int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721206    10/04/2016 11:08:47 AM\n",
      "208989    10/07/2011 10:03:00 PM\n",
      "571939    11/23/2012 07:12:00 AM\n",
      "Name: Event Clearance Date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(spir_drop_unused_col['Event Clearance Date'].sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate missing values"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d69d0d44c3579cef8f6b53da4bdf417e2460497c27e188711da66de3978a2224"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
