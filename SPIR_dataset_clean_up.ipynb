{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file takes the original dataset from Kaggle and converts the dataset into Python-readable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "import copy\n",
    "sys.path.append('C:\\\\Users\\\\chery\\\\Documents\\\\SeattlePolice911Response')\n",
    "from utils.baseML import BaseML\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_original = pd.read_csv(\"Seattle_Police_Department_911_Incident_Response.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spir_original.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Drop unused Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns= ['CAD CDW ID', 'CAD Event Number', 'General Offense Number', 'Hundred Block Location', 'District/Sector',\n",
    "       'Zone/Beat', 'Longitude', 'Latitude',\n",
    "       'Incident Location']\n",
    "\n",
    "spir_drop_unused_col = spir_original.drop(labels=drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of unique census tracts. This is used to pull data from the US Census API 5 year American Community Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_tracts = spir_drop_unused_col[\"Census Tract\"].unique()\n",
    "census_tracts = pd.DataFrame(census_tracts, columns=[\"census_tracts\"])\n",
    "census_tracts.dropna(axis =0, inplace=True)\n",
    "census_tracts.census_tracts=census_tracts.census_tracts.apply(format_tract)\n",
    "census_tracts.census_tracts = pd.Series(census_tracts.census_tracts.unique())\n",
    "census_tracts.dropna(axis=0, inplace=True)\n",
    "census_tracts.to_csv(\"census_tracts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_dropna = spir_drop_unused_col.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seattle_Police_ML(BaseML):\n",
    "\n",
    "    def dayDifference(self, fdate, ldate):\n",
    "        delta = ldate - fdate\n",
    "        return(delta)\n",
    "\n",
    "    #Transform At Scene Time and Event Clearance Date to datetime objects. Create time_at_scene parameter\n",
    "    def transform_times(self):\n",
    "        dt_format = '%m/%d/%Y %I:%M:%S %p'\n",
    "        self.df['at_scene_time'] = self.df[\"At Scene Time\"].apply(lambda x: datetime.strptime(x, dt_format))\n",
    "        self.df['event_clear_time']=self.df[\"Event Clearance Date\"].apply(lambda x: datetime.strptime(x, dt_format))\n",
    "        self.df['time_at_scene'] = self.df.apply(lambda x: pd.to_timedelta(self.dayDifference(x[\"at_scene_time\"], x[\"event_clear_time\"])), axis = 1)\n",
    "        self.df.drop([\"At Scene Time\", \"Event Clearance Date\"], axis = 1, inplace = True)\n",
    "        print(self.df.sample(3))\n",
    "\n",
    "    #Bins the time_at_scene data. Unused for this project\n",
    "    def simplify_times(self):\n",
    "        bins = (\n",
    "            pd.Timedelta(minutes = 0),\n",
    "            pd.Timedelta(minutes = 30),\n",
    "            pd.Timedelta(minutes = 60),\n",
    "            pd.Timedelta(hours = 4),\n",
    "            pd.Timedelta(hours = 8),\n",
    "            pd.Timedelta(hours = 12),\n",
    "            pd.Timedelta(days = 1),\n",
    "            pd.Timedelta(days = 36500)\n",
    "        )\n",
    "\n",
    "        labels = ['< 30min', '30-60min','1-4hrs', '4-8hrs','8-12hrs','12-24hrs', '24hrs+']\n",
    "\n",
    "        return pd.cut(self.df['time_at_scene'], bins, labels = labels)\n",
    "\n",
    "    def map_func(self,parameter_df, x):\n",
    "        try:\n",
    "            return parameter_df.loc[math.floor(x[\"Census Tract\"]), str(datetime.strptime(x.at_scene_time, \"%Y-%m-%d %H:%M:%S\").year)]\n",
    "        except KeyError:\n",
    "            return None\n",
    "            pass\n",
    "            #print(math.floor(x[\"Census Tract\"]))\n",
    "\n",
    "    #Uses CSV files with census data to fill in parameters in the dataset\n",
    "    def add_census_data(self, census_filename, parameter_name):\n",
    "        parameter_df = pd.read_csv(census_filename, index_col=1)\n",
    "        print(self.df[\"Census Tract\"].sample(3))\n",
    "        self.df[parameter_name]=self.df.apply(lambda x: self.map_func(parameter_df, x), axis=1)\n",
    "        \n",
    "    #normalizes features    \n",
    "    def normalize_features(self):\n",
    "        scaler = preprocessing.StandardScaler().fit(self.df)\n",
    "        df_scaled = scaler.transform(self.df)\n",
    "        self.df_normalized = pd.DataFrame(df_scaled, columns = self.df.columns, dtype= 'int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final = Seattle_Police_ML()\n",
    "spir_final.df = copy.deepcopy(spir_dropna)\n",
    "spir_final.transform_times()\n",
    "spir_final.simplify_times()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df.to_csv(\"SPIR_transformed_times.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final = Seattle_Police_ML(\"SPIR_transformed_times.csv\")\n",
    "print(spir_final.df[\"Census Tract\"].sample(3))\n",
    "spir_final.add_census_data(\"white_percent.csv\",\"white\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.add_census_data(\"total_pop_by_tract.csv\",\"total_pop\")\n",
    "spir_final.add_census_data(\"male_percent.csv\",\"male\")\n",
    "spir_final.add_census_data(\"notUScitizen_percent.csv\",\"notUScitizen\")\n",
    "spir_final.add_census_data(\"asian_percent.csv\",\"asian\")\n",
    "spir_final.add_census_data(\"black_percent.csv\",\"black\")\n",
    "spir_final.add_census_data(\"native_percent.csv\",\"native\")\n",
    "spir_final.add_census_data(\"other_race_percent.csv\",\"other_race\")\n",
    "spir_final.add_census_data(\"two_races_percent.csv\",\"two_races\")\n",
    "spir_final.add_census_data(\"some_college_percent.csv\",\"some_college\")\n",
    "spir_final.add_census_data(\"bachelors_percent.csv\",\"bachelors\")\n",
    "spir_final.add_census_data(\"grad_deg_percent.csv\",\"grad_deg\")\n",
    "spir_final.add_census_data(\"under18MC_percent.csv\",\"under18MC\")\n",
    "spir_final.add_census_data(\"under18MS_percent.csv\",\"under18MS\")\n",
    "spir_final.add_census_data(\"under18FS_percent.csv\",\"under18FS\")\n",
    "spir_final.add_census_data(\"under18T_percent.csv\",\"under18T\")\n",
    "spir_final.add_census_data(\"income_by_tract.csv\", \"income\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df.to_csv(\"SPIR_census_added.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Encode \"Initial Type Description\" parameter</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df['Initial Type Description'] = spir_final.df['Initial Type Description'].astype('category')\n",
    "print(spir_final.df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df[\"initial_type_desc_cat\"] = spir_final.df[\"Initial Type Description\"].cat.codes\n",
    "print(spir_final.df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create additional parameters for time of day (AM or PM), day of the week, month, and year. Convert time_at_scene to seconds</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df.at_scene_time = spir_final.df.at_scene_time.astype('datetime64')\n",
    "spir_final.df.event_clear_time = spir_final.df.event_clear_time.astype('datetime64')\n",
    "spir_final.df.time_at_scene = pd.to_timedelta(spir_final.df.time_at_scene)\n",
    "\n",
    "print(spir_final.df.time_at_scene.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noon = datetime(2021, 11, 12,hour = 12)\n",
    "spir_final.df[\"at_scene_time_pm\"] = spir_final.df.at_scene_time.apply(lambda x: 0 if x.hour < noon.hour else 1)\n",
    "spir_final.df[\"event_clear_time_pm\"] = spir_final.df.event_clear_time.apply(lambda x: 0 if x.hour < noon.hour else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df[\"at_scene_time_weekday\"] = spir_final.df.at_scene_time.apply(datetime.weekday)\n",
    "spir_final.df[\"event_clear_time_weekday\"] = spir_final.df.event_clear_time.apply(datetime.weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df[\"at_scene_time_month\"] = spir_final.df.at_scene_time.apply(lambda x: x.month)\n",
    "spir_final.df[\"event_clear_time_month\"] = spir_final.df.event_clear_time.apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df[\"at_scene_time_year\"] = spir_final.df.at_scene_time.apply(lambda x: x.year)\n",
    "spir_final.df[\"event_clear_time_year\"] = spir_final.df.event_clear_time.apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "spir_final.df[\"time_at_scene_seconds\"] = spir_final.df.time_at_scene.apply(timedelta.total_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spir_final.df.to_csv(\"SPIR_encoded_2021116.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d69d0d44c3579cef8f6b53da4bdf417e2460497c27e188711da66de3978a2224"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
